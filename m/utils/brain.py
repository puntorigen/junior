# methods for choosing the best LLM model, launch local LLM server and interact with it
# also to provide a single LLM query endpoint with schema enforcement capabilities and 
# cost tracking if needed